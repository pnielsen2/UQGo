{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: numba.jit seems to not be available. Using a dummy decorator for numba.jit() ...\n",
      "If you want the speed up brought by numba.jit, try to manually install numba and check that it works (installing llvmlite can be tricky, cf. https://github.com/numba/numba#custom-python-environments\n",
      "Info: Using the Jupyter notebook version of the tqdm() decorator, tqdm_notebook() ...\n",
      "Warning: numba.jit seems to not be available. Using a dummy decorator for numba.jit() ...\n",
      "If you want the speed up brought by numba.jit, try to manually install numba and check that it works (installing llvmlite can be tricky, cf. https://github.com/numba/numba#custom-python-environments\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pettingzoo.classic import go_v5\n",
    "from SMPyBandits import Policies\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import warnings\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixedMOSSEcomputeAllIndex(self):\n",
    "    \"\"\" Compute the current indexes for all arms, in a vectorized manner.\"\"\"\n",
    "    pulls_of_suboptimal_arms = np.sum(self.pulls[self.pulls < np.sqrt(self.t)])\n",
    "    if pulls_of_suboptimal_arms > 0:\n",
    "        indexes = (self.rewards / self.pulls) + np.sqrt(0.5 * np.maximum(0, np.log(self.t / pulls_of_suboptimal_arms)) / self.pulls)\n",
    "    else:\n",
    "        indexes = (self.rewards / self.pulls) + np.sqrt(0.5 * np.maximum(0, np.log(self.t / (self.nbArms * self.pulls))) / self.pulls)\n",
    "    # indexes[self.pulls < 1] = float('+inf')\n",
    "    self.index[:] = indexes\n",
    "Policies.MOSSExperimental.computeAllIndex = fixedMOSSEcomputeAllIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Multi-Armed Bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meta_policy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/philipnielsen/Documents/Code/UQGo/tabular_tree_experiments.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/philipnielsen/Documents/Code/UQGo/tabular_tree_experiments.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# meta_policy = Policies.UCB(len(policy_algorithm_list))\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/philipnielsen/Documents/Code/UQGo/tabular_tree_experiments.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# squares = np.zeros(len(policy_algorithm_list))\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/philipnielsen/Documents/Code/UQGo/tabular_tree_experiments.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/philipnielsen/Documents/Code/UQGo/tabular_tree_experiments.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# meta_choice = meta_policy.choice()\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/philipnielsen/Documents/Code/UQGo/tabular_tree_experiments.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     meta_choice \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmin(meta_policy\u001b[39m.\u001b[39mpulls)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/philipnielsen/Documents/Code/UQGo/tabular_tree_experiments.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mchoice:\u001b[39m\u001b[39m{\u001b[39;00mmeta_choice\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/philipnielsen/Documents/Code/UQGo/tabular_tree_experiments.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     policy_algorithm \u001b[39m=\u001b[39m policy_algorithm_list[meta_choice]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'meta_policy' is not defined"
     ]
    }
   ],
   "source": [
    "# meta_policy = Policies.UCB(len(policy_algorithm_list))\n",
    "# squares = np.zeros(len(policy_algorithm_list))\n",
    "while True:\n",
    "    # meta_choice = meta_policy.choice()\n",
    "    meta_choice = np.argmin(meta_policy.pulls)\n",
    "    print(f'choice:{meta_choice}')\n",
    "    policy_algorithm = policy_algorithm_list[meta_choice]\n",
    "    num_arms = 10\n",
    "    num_fictitious_pulls = 1000\n",
    "    random_fictitious = False\n",
    "    if random_fictitious:\n",
    "        fictitious_pulls = np.random.dirichlet(num_arms*[1])*num_fictitious_pulls\n",
    "        fictitious_empirical_means = np.random.random(num_arms)\n",
    "    else:\n",
    "        fictitious_pulls = np.array(num_arms*[0])\n",
    "        fictitious_empirical_means = np.array(num_arms*[0])\n",
    "\n",
    "    # print(fictitious_pulls)\n",
    "\n",
    "    fictitious_rewards = fictitious_pulls * fictitious_empirical_means\n",
    "    # print(fictitious_rewards)\n",
    "    # policy = Policies.UCBoost_bq_h_lb(num_arms)\n",
    "    policy = policy_algorithm(num_arms)\n",
    "    # policy = CPUCB(num_arms)\n",
    "    # policy = klUCB(num_arms)\n",
    "    policy.pulls = fictitious_pulls\n",
    "    # print(policy.pulls)\n",
    "    policy.rewards = fictitious_rewards\n",
    "    # true_probs = np.random.random(num_arms)\n",
    "    # true_probs = np.array([.5]* num_arms)\n",
    "    true_probs = scipy.stats.beta.rvs(50,50,size=num_arms)\n",
    "    # print(true_probs)\n",
    "\n",
    "    for i in range(10000):\n",
    "        # print(policy.index)\n",
    "        action = policy.choice()\n",
    "        reward = np.random.binomial(1,true_probs[action])\n",
    "        policy.getReward(action, reward)\n",
    "        # policy.pulls[action]+=1\n",
    "        # policy.rewards[action]+=reward\n",
    "        # print(action,reward)\n",
    "        # print(policy.pulls)\n",
    "        # policy.computeAllIndex()\n",
    "    # print(true_probs)\n",
    "    # print(true_probs.round(4))\n",
    "    print('pulls:')\n",
    "    print(policy.pulls)\n",
    "    print('rewards:')\n",
    "    print(policy.rewards)\n",
    "    # print(policy.rewards/policy.pulls)\n",
    "    regret = policy.pulls.sum()*true_probs.max()-(policy.pulls*true_probs).sum()\n",
    "    print(f'regret:{regret}')\n",
    "    meta_policy.getReward(meta_choice, -regret)\n",
    "    squares[meta_choice]+=regret**2\n",
    "    print('meta mean rewards')\n",
    "    print(meta_policy.rewards/(meta_policy.pulls+.0001))\n",
    "    print('meta pulls:')\n",
    "    score = -meta_policy.rewards/(meta_policy.pulls+.0001)\n",
    "    stdev = np.sqrt(squares/(meta_policy.pulls+.0001)-score**2)\n",
    "    mean_stdev = stdev/np.sqrt((meta_policy.pulls+.0001))\n",
    "    print((pd.DataFrame({'Name':policy_algorithm_names, 'score': score, 'mean stdev': mean_stdev, 'stdev': stdev, 'pulls': meta_policy.pulls})).sort_values(by='score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_algorithm_list = [Policies.ProbabilityPursuit, Policies.EmpiricalMeans, Policies.UCB, Policies.UCBmin, Policies.UCBplus, Policies.UCBVtuned, Policies.MOSS, Policies.MOSSAnytime, Policies.MOSSExperimental, Policies.klUCB, Policies.klUCBloglog, Policies.klUCBPlus, Policies.klUCBswitchAnytime, Policies.DMED, Policies.DMEDPlus, Policies.AdBandits, Policies.LM_DSEE, Policies.BESA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_algorithm_names = ['ProbabilityPursuit', 'EmpiricalMeans', 'UCB', 'UCBmin', 'UCBplus', 'UCBVtuned', 'MOSS', 'MOSSAnytime', 'MOSSExperimental', 'klUCB', 'klUCBloglog', 'klUCBPlus', 'klUCBswitchAnytime', 'DMED', 'DMEDPlus', 'AdBandits', 'LM_DSEE', 'BESA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame({'Name':policy_algorithm_names, 'score': -meta_policy.rewards/(meta_policy.pulls+.0001), 'pulls': meta_policy.pulls})).sort_values(by='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(policy_algorithm_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(len(policy_algorithm_list)):\n",
    "    try:\n",
    "        results.append(benchmark(policy_algorithm_list[i]))\n",
    "    except:\n",
    "        results.append(f'fail:{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Armed Bandit Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetically-Generated Tree-based Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, mean, game_length, depth, num_arms):\n",
    "        self.mean = mean\n",
    "        self.game_length = game_length\n",
    "        self.depth = depth\n",
    "        self.num_arms = num_arms\n",
    "        self.policy = klUCBPlus(num_arms)\n",
    "        self.fictitious_pulls = np.array(num_arms*[1])\n",
    "        self.fictitious_rewards = np.array(num_arms*[0])\n",
    "        self.policy.pulls = self.fictitious_pulls.copy()\n",
    "        self.policy.rewards = self.fictitious_rewards.copy()\n",
    "        if game_length == depth:\n",
    "            self.action_means = scipy.stats.bernoulli.rvs(self.mean, size=num_arms)\n",
    "        else:\n",
    "            self.action_means = scipy.stats.beta.rvs(self.mean*9+.001,(1-self.mean)*9+.001,size=num_arms)\n",
    "            # self.action_means = self.action_means*self.mean/self.action_means.mean()\n",
    "        self.next_nodes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 25\n",
    "root_node = Node(mean=.5, game_length = size, depth = 1, num_arms = size)\n",
    "writer = SummaryWriter()\n",
    "reward_list = []\n",
    "big_number = 1e10\n",
    "win_condition = 100\n",
    "i = 0\n",
    "while True:\n",
    "    node=root_node\n",
    "    node_action_list = []\n",
    "    while True:\n",
    "        action = node.policy.choice()\n",
    "        node_action_list.append((node,action))\n",
    "        if node.depth == node.game_length:\n",
    "            reward = node.action_means[action]\n",
    "            writer.add_scalar('Reward', reward, str(i))\n",
    "            reward_list.append(reward)\n",
    "            break\n",
    "        else:\n",
    "            node = node.next_nodes.setdefault(action, Node(mean=node.action_means[action], game_length=node.game_length, depth=node.depth+1, num_arms=node.num_arms))\n",
    "    node_solved = False\n",
    "    for node, action in reversed(node_action_list):\n",
    "        if node_solved !=0:\n",
    "            node.policy.pulls[action] = -node_solved * big_number\n",
    "            node.fictitious_rewards[action] \n",
    "            node.policy.pulls[action] +=1\n",
    "        else:\n",
    "            node.policy.getReward(action, (reward if node.depth%2 else 1-reward))\n",
    "        node_solved = 1 if any((node.policy.rewards==big_number)==(node.policy.pulls==big_number)) else (-1 if all(node.policy.rewards==-big_number) else 0)\n",
    "    if node_action_list[-1][0].depth % 2 == reward:\n",
    "        node_action_list[-2][0].policy.rewards[node_action_list[-2][1]] = -big_number\n",
    "    if len(reward_list)>win_condition and ((np.array(reward_list[-win_condition:])==1).all() or (np.array(reward_list[-win_condition:])==0).all()):\n",
    "        break\n",
    "    i +=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoNode():\n",
    "    def __init__(self, num_arms, legal_actions, policy_algorithm, player='black_0', state=None):\n",
    "        self.num_arms = num_arms\n",
    "        self.legal_actions = legal_actions\n",
    "        self.player = player\n",
    "        self.state = state\n",
    "        self.policy_algorithm = policy_algorithm\n",
    "        self.policy = self.policy_algorithm(num_arms)\n",
    "        self.fictitious_pulls = np.ones(num_arms)\n",
    "        self.fictitious_rewards = np.ones(num_arms) / 2\n",
    "        self.policy.pulls = self.fictitious_pulls.copy()\n",
    "        self.policy.rewards = self.fictitious_rewards.copy()\n",
    "        self.policy.t = self.policy.pulls.sum()\n",
    "        self.next_nodes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_algorithm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(policy_algorithm):\n",
    "    env = go_v5.env(board_size = 3, komi = 3.5)\n",
    "    env.reset(seed=42)\n",
    "    root_node = GoNode(num_arms = env.last()[0]['action_mask'].sum(), legal_actions = env.last()[0]['action_mask'].nonzero()[0], policy_algorithm=policy_algorithm)\n",
    "    winner_list = []\n",
    "    unique_nodes = 0\n",
    "    big_number = 1e10\n",
    "    win_condition = 100\n",
    "    i = 0\n",
    "    while True:\n",
    "        node = root_node\n",
    "        node_action_list = []\n",
    "        observation, reward, termination, truncation, info = env.last()\n",
    "        mask = observation[\"action_mask\"]\n",
    "        for agent in env.agent_iter():\n",
    "            if termination or truncation:\n",
    "                action = None\n",
    "                winner = reward if agent=='black_0' else -reward\n",
    "                winner = (winner + 1)/2\n",
    "                winner_list.append(winner)\n",
    "                break\n",
    "            policy_choice = node.policy.choice()\n",
    "            action = node.legal_actions[policy_choice]\n",
    "            node_action_list.append((node,policy_choice))\n",
    "            env.step(action)\n",
    "            observation, reward, termination, truncation, info = env.last()\n",
    "            mask = observation[\"action_mask\"]\n",
    "            if policy_choice not in node.next_nodes:\n",
    "                unique_nodes +=1\n",
    "            node = node.next_nodes.setdefault(policy_choice, GoNode(num_arms=np.count_nonzero(observation['action_mask']), legal_actions = mask.nonzero()[0], policy_algorithm=policy_algorithm, player = 'white_0' if node.player=='black_0' else 'black_0'))\n",
    "        env.close()\n",
    "\n",
    "        if {'black_0':1,'white_0':0}[node_action_list[-1][0].player] == winner:\n",
    "            node_solved=-1\n",
    "        else:\n",
    "            node_solved=1\n",
    "        for node, action in reversed(node_action_list):\n",
    "            if node_solved !=0:\n",
    "                # node.policy.rewards[action] = -node_solved * big_number\n",
    "                # node.policy.pulls[action] +=1\n",
    "                # node.policy.t +=1\n",
    "                node.policy.getReward(action, -node_solved*big_number)\n",
    "            else:\n",
    "                node.policy.getReward(action, (winner if node.player=='black_0' else 1-winner))\n",
    "            node_solved = 1 if any(node.policy.rewards==big_number) else (-1 if all(node.policy.rewards==-big_number) else 0)\n",
    "        \n",
    "        if len(winner_list)>win_condition and ((np.array(winner_list[-win_condition:])==1).all() or (np.array(winner_list[-win_condition:])==0).all()):\n",
    "            break\n",
    "        env.reset(seed=42)\n",
    "        i+=1\n",
    "    return unique_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klUCBPlus_benchmark_results = []\n",
    "MOSSExperimental_benchmark_results = []\n",
    "while True:\n",
    "    if len(klUCBPlus_benchmark_results) <= len(MOSSExperimental_benchmark_results):\n",
    "        result = benchmark(Policies.klUCBPlus)\n",
    "        klUCBPlus_benchmark_results.append(result)\n",
    "        print(f'klUCBPlus: {result}')\n",
    "    else:\n",
    "        result = benchmark(Policies.MOSSExperimental)\n",
    "        MOSSExperimental_benchmark_results.append(result)\n",
    "        print(f'MOSSExperimental: {result}')\n",
    "    print(len(klUCBPlus_benchmark_results), len(MOSSExperimental_benchmark_results))\n",
    "    # bins = np.linspace(min(klUCBPlus_benchmark_results+MOSSExperimental_benchmark_results), max(klUCBPlus_benchmark_results+MOSSExperimental_benchmark_results), 20)\n",
    "    # plt.hist(klUCBPlus_benchmark_results, bins,alpha=.5)\n",
    "    # plt.hist(MOSSExperimental_benchmark_results, bins, alpha=.5)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  1.,  2.,  3., 14.,  9.,  9.,  8.,  3.,  3.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
       " array([115066.        , 123648.51282051, 132231.02564103, 140813.53846154,\n",
       "        149396.05128205, 157978.56410256, 166561.07692308, 175143.58974359,\n",
       "        183726.1025641 , 192308.61538462, 200891.12820513, 209473.64102564,\n",
       "        218056.15384615, 226638.66666667, 235221.17948718, 243803.69230769,\n",
       "        252386.20512821, 260968.71794872, 269551.23076923, 278133.74358974,\n",
       "        286716.25641026, 295298.76923077, 303881.28205128, 312463.79487179,\n",
       "        321046.30769231, 329628.82051282, 338211.33333333, 346793.84615385,\n",
       "        355376.35897436, 363958.87179487, 372541.38461538, 381123.8974359 ,\n",
       "        389706.41025641, 398288.92307692, 406871.43589744, 415453.94871795,\n",
       "        424036.46153846, 432618.97435897, 441201.48717949, 449784.        ]),\n",
       " <BarContainer object of 39 artists>)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1920x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(min(klUCBPlus_benchmark_results+MOSSExperimental_benchmark_results), max(klUCBPlus_benchmark_results+MOSSExperimental_benchmark_results), 40)\n",
    "plt.hist(klUCBPlus_benchmark_results, bins,alpha=.5)\n",
    "plt.hist(MOSSExperimental_benchmark_results, bins, alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False, False])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([1,1,1,0,0])\n",
    "d = np.array([0,0,1,1,1])\n",
    "(c==1)==(d==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "env = go_v5.env(board_size = 3, komi = 3.5)\n",
    "policy_algorithm=Policies.MOSSExperimental\n",
    "env.reset(seed=42)\n",
    "last = env.last()\n",
    "root_node = GoNode(num_arms = last[0]['action_mask'].sum(), legal_actions = last[0]['action_mask'].nonzero()[0], policy_algorithm=policy_algorithm, state = last[0]['observation'].transpose((2,1,0)))\n",
    "winner_list = []\n",
    "big_number = 1e10\n",
    "win_condition = 100\n",
    "i = 0\n",
    "while True:\n",
    "    node = root_node\n",
    "    node_action_list = []\n",
    "    observation, reward, termination, truncation, info = env.last()\n",
    "    state = observation['observation'].transpose((2,1,0))\n",
    "    mask = observation[\"action_mask\"]\n",
    "    for agent in env.agent_iter():\n",
    "        if termination or truncation:\n",
    "            action = None\n",
    "            winner = reward if agent=='black_0' else -reward\n",
    "            winner = (winner + 1)/2\n",
    "            winner_list.append(winner)\n",
    "            writer.add_scalar('Winner', winner, str(i))\n",
    "            break\n",
    "        policy_choice = node.policy.choice()\n",
    "        action = node.legal_actions[policy_choice]\n",
    "        node_action_list.append((node,policy_choice))\n",
    "        env.step(action)\n",
    "        observation, reward, termination, truncation, info = env.last()\n",
    "        state = observation['observation'].transpose((2,1,0))\n",
    "        mask = observation[\"action_mask\"]\n",
    "        num_arms = np.count_nonzero(mask)\n",
    "        node = node.next_nodes.setdefault(policy_choice, GoNode(num_arms=num_arms, legal_actions = mask.nonzero()[0], policy_algorithm=policy_algorithm if num_arms > 3 else Policies.klUCBPlus, player = 'white_0' if node.player=='black_0' else 'black_0', state=state))\n",
    "    env.close()\n",
    "\n",
    "    if {'black_0':1,'white_0':0}[node_action_list[-1][0].player] == winner:\n",
    "        node_solved=-1\n",
    "    else:\n",
    "        node_solved=1\n",
    "    for node, action in reversed(node_action_list):\n",
    "        if node_solved !=0:\n",
    "            node.policy.rewards[action] = big_number if node_solved==-1 else .5\n",
    "            node.policy.pulls[action]=big_number\n",
    "            # node.policy.pulls[action] +=1\n",
    "        else:\n",
    "            node.policy.getReward(action, (winner if node.player=='black_0' else 1-winner))\n",
    "        node_solved = 1 if any(node.policy.rewards==big_number) else (-1 if (all(node.policy.rewards==.5) and all(node.policy.pulls==big_number)) else 0)\n",
    "    \n",
    "    # if len(winner_list)>win_condition and ((np.array(winner_list[-win_condition:])==1).all() or (np.array(winner_list[-win_condition:])==0).all()):\n",
    "    #     break\n",
    "    if any(root_node.policy.rewards==big_number):\n",
    "        break\n",
    "    env.reset(seed=42)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.250e+01, 1.150e+01, 1.950e+01, 1.375e+02, 1.000e+10, 8.950e+01,\n",
       "       7.250e+01, 1.315e+02, 3.850e+01, 5.000e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_node.policy.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 3, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.last()[0]['observation'].transpose((2,1,0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.250e+01, 1.150e+01, 1.950e+01, 1.375e+02, 1.000e+10, 8.950e+01,\n",
       "       7.250e+01, 1.315e+02, 3.850e+01, 5.000e-01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_node.policy.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_data(node):\n",
    "    states = [node.state]\n",
    "    num_arms = len(root_node.state[0].flatten())+1\n",
    "    a = np.zeros(num_arms)\n",
    "    a[node.legal_actions] = node.policy.rewards\n",
    "    alphas = [a]\n",
    "    p = np.zeros(num_arms)\n",
    "    p[node.legal_actions] = node.policy.pulls\n",
    "    betas = [p-a]\n",
    "    for next_node in node.next_nodes.values():\n",
    "        next_states, next_alphas, next_betas = pull_data(next_node)\n",
    "        states += next_states\n",
    "        alphas += next_alphas\n",
    "        betas += next_betas\n",
    "    return states, alphas, betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, target_alphas, target_betas = pull_data(root_node)\n",
    "target_alphas, target_betas = torch.FloatTensor(np.array(target_alphas)), torch.FloatTensor(np.array(target_betas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([148907, 10])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_alphas.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91131084"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = torch.FloatTensor(np.array(states))\n",
    "states.element_size()*states.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([148907, 17, 3, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Conv2d(17, 32, 3, 1, padding='same')] + \\\n",
    "            [nn.Conv2d(32, 32, 3, 1, padding='same') for i in range(2)] + \\\n",
    "            [nn.Conv2d(32, 2, 3, 1, padding='same')])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers)-1):\n",
    "            x = self.layers[i](x)\n",
    "            x = F.relu(x)\n",
    "        out = torch.flatten(self.layers[-1](x), -2, -1)\n",
    "        passes = x[:,:2,:,:].mean(axis=(-1,-2))\n",
    "        out = torch.cat((out, passes.unsqueeze(-1)), axis=-1)\n",
    "        alphas = torch.exp(out[:,0,:])\n",
    "        betas=torch.exp(out[:,1,:])\n",
    "        return alphas, betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54., 21.,  4.,  3., 67., 15., 30., 11.,  3.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_node.next_nodes[0].policy.pulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function to choose + cross-validate loss and iterations and network architecture other inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, type):\n",
    "        super(Net, self).__init__()\n",
    "        if type == 1:\n",
    "            self.layers = nn.ModuleList(\n",
    "                [nn.Conv2d(17, 32, 3, 1, padding='same')] + \\\n",
    "                [nn.Conv2d(32, 32, 3, 1, padding='same')] + \\\n",
    "                [nn.Conv2d(32, 2, 3, 1, padding='same')])\n",
    "        elif type == 2:\n",
    "            self.layers = nn.ModuleList(\n",
    "                [nn.Conv2d(17, 32, 3, 1, padding='same')] + \\\n",
    "                [nn.Conv2d(32, 32, 3, 1, padding='same') for _ in range(2)] + \\\n",
    "                [nn.Conv2d(32, 2, 3, 1, padding='same')])\n",
    "        elif type == 3:\n",
    "            self.layers = nn.ModuleList(\n",
    "                [nn.Conv2d(17, 32, 3, 1, padding='same')] + \\\n",
    "                [nn.Conv2d(32, 32, 3, 1, padding='same') for _ in range(4)] + \\\n",
    "                [nn.Conv2d(32, 2, 3, 1, padding='same')])\n",
    "        elif type == 4:\n",
    "            self.layers = nn.ModuleList(\n",
    "                [nn.Conv2d(17, 64, 3, 1, padding='same')] + \\\n",
    "                [nn.Conv2d(64, 32, 3, 1, padding='same')] + \\\n",
    "                [nn.Conv2d(32, 16, 3, 1, padding='same')] + \\\n",
    "                [nn.Conv2d(16, 2, 3, 1, padding='same')])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers)-1):\n",
    "            x = self.layers[i](x)\n",
    "            x = F.relu(x)\n",
    "        out = torch.flatten(self.layers[-1](x), -2, -1)\n",
    "        passes = x[:,:2,:,:].mean(axis=(-1,-2))\n",
    "        out = torch.cat((out, passes.unsqueeze(-1)), axis=-1)\n",
    "        alphas = torch.exp(out[:,0,:])\n",
    "        betas=torch.exp(out[:,1,:])\n",
    "        return alphas, betas\n",
    "\n",
    "def loss1(target_beta_batches, target_alpha_batches, p_hat, s, pulls):\n",
    "    return (target_beta_batches*p_hat**2 + target_alpha_batches*(1-p_hat)**2 + p_hat*(1-p_hat)/(s+1)*pulls).mean()\n",
    "\n",
    "def loss2(p_hat, target_probs):\n",
    "    return ((p_hat-target_probs)**2).mean()\n",
    "\n",
    "def loss3(target_beta_batches, target_alpha_batches, p_hat):\n",
    "    return (target_beta_batches*p_hat**2 + target_alpha_batches*(1-p_hat)**2).mean()\n",
    "\n",
    "def loss4(target_alpha_batches, s, alphas):\n",
    "    return (target_alpha_batches*(torch.digamma(s)-torch.digamma(alphas))).mean()\n",
    "\n",
    "def tuning(network, loss_func):\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-5)\n",
    "\n",
    "    batch_size = 64\n",
    "    \n",
    "    train_target_alphas, val_target_alphas, test_target_alphas = torch.split(target_alphas, [int(len(target_alphas)*0.7), int(len(target_alphas)*0.15), int(len(target_alphas)*0.15) + 1])\n",
    "    train_target_betas, val_target_betas, test_target_betas = torch.split(target_betas, [int(len(target_betas)*0.7), int(len(target_betas)*0.15), int(len(target_betas)*0.15) + 1])\n",
    "    train_states, val_states, test_states = torch.split(states, [int(len(states)*0.7), int(len(states)*0.15), int(len(states)*0.15) + 1])\n",
    "    \n",
    "    train_target_alpha_batches = torch.split(train_target_alphas, batch_size)\n",
    "    train_target_beta_batches = torch.split(train_target_betas, batch_size)\n",
    "    train_batches = torch.split(train_states, batch_size)\n",
    "    ma = 0\n",
    "        \n",
    "    for epoch in range(10):\n",
    "        print(f'epoch:{epoch}')\n",
    "        for i in range(len(train_batches)):\n",
    "            optimizer.zero_grad()\n",
    "            alphas, betas = network(train_batches[i])\n",
    "\n",
    "            s = alphas+betas\n",
    "            p_hat = alphas/s\n",
    "            \n",
    "            pulls = train_target_alpha_batches[i] + train_target_beta_batches[i]\n",
    "            target_probs = train_target_alpha_batches[i]/pulls\n",
    "            target_probs[target_probs != target_probs] = 0\n",
    "\n",
    "            if loss_func == loss1:\n",
    "                train_loss = loss1(train_target_beta_batches[i], train_target_alpha_batches[i], p_hat, s, pulls)\n",
    "            elif loss_func == loss2:\n",
    "                train_loss = loss2(p_hat, target_probs)\n",
    "            elif loss_func == loss3:\n",
    "                train_loss = loss3(train_target_beta_batches[i], train_target_alpha_batches[i], p_hat)\n",
    "            elif loss_func == loss4:\n",
    "                train_loss = loss4(train_target_alpha_batches[i], s, alphas)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 500 == 0:\n",
    "                print(train_loss.item())\n",
    "    \n",
    "    val_target_alpha_batches, val_target_beta_batches = torch.split(val_target_alphas, batch_size), torch.split(val_target_betas, batch_size)\n",
    "    val_batches = torch.split(val_states, batch_size)\n",
    "    val_batch_loss = []\n",
    "    for i in range(len(val_batches)):\n",
    "        optimizer.zero_grad()\n",
    "        alphas, betas = network(val_batches[i])\n",
    "\n",
    "        s = alphas+betas\n",
    "        p_hat = alphas/s\n",
    "        \n",
    "        pulls = val_target_alpha_batches[i] + val_target_beta_batches[i]\n",
    "        target_probs = val_target_alpha_batches[i]/pulls\n",
    "        target_probs[target_probs != target_probs] = 0\n",
    "\n",
    "        val_batch_loss += [loss2(p_hat, target_probs).item()]\n",
    "\n",
    "    return val_batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "88210712.0\n",
      "85295904.0\n",
      "122494296.0\n",
      "147094528.0\n",
      "epoch:1\n",
      "73216048.0\n",
      "55481044.0\n",
      "95172432.0\n",
      "61516140.0\n",
      "epoch:2\n",
      "50347864.0\n",
      "27722116.0\n",
      "81146464.0\n",
      "43025912.0\n",
      "epoch:3\n",
      "39903776.0\n",
      "19737014.0\n",
      "69999888.0\n",
      "35717704.0\n",
      "epoch:4\n",
      "33660056.0\n",
      "16037624.0\n",
      "58396920.0\n",
      "31176740.0\n",
      "epoch:5\n",
      "29504576.0\n",
      "13652006.0\n",
      "48730452.0\n",
      "27921148.0\n",
      "epoch:6\n",
      "26805262.0\n",
      "12025821.0\n",
      "41818120.0\n",
      "25353174.0\n",
      "epoch:7\n",
      "25088038.0\n",
      "10896904.0\n",
      "36782560.0\n",
      "23264476.0\n",
      "epoch:8\n",
      "24017164.0\n",
      "10133387.0\n",
      "32833702.0\n",
      "21578876.0\n",
      "epoch:9\n",
      "23288484.0\n",
      "9617570.0\n",
      "29573760.0\n",
      "20212572.0\n",
      "epoch:0\n",
      "0.27550700306892395\n",
      "0.11030910164117813\n",
      "0.07318033277988434\n",
      "0.050869204103946686\n",
      "epoch:1\n",
      "0.08783064782619476\n",
      "0.08587642759084702\n",
      "0.06478781998157501\n",
      "0.04873128980398178\n",
      "epoch:2\n",
      "0.08339013159275055\n",
      "0.08356084674596786\n",
      "0.06125699728727341\n",
      "0.044765327125787735\n",
      "epoch:3\n",
      "0.06830383837223053\n",
      "0.07089269906282425\n",
      "0.05146122723817825\n",
      "0.040163736790418625\n",
      "epoch:4\n",
      "0.05642489716410637\n",
      "0.062336552888154984\n",
      "0.04761958867311478\n",
      "0.0390901193022728\n",
      "epoch:5\n",
      "0.05400124937295914\n",
      "0.058390598744153976\n",
      "0.04572264477610588\n",
      "0.03933129459619522\n",
      "epoch:6\n",
      "0.05043914169073105\n",
      "0.052730459719896317\n",
      "0.043454356491565704\n",
      "0.03962754085659981\n",
      "epoch:7\n",
      "0.04620911180973053\n",
      "0.04565351456403732\n",
      "0.04099975898861885\n",
      "0.038424305617809296\n",
      "epoch:8\n",
      "0.043366335332393646\n",
      "0.041655875742435455\n",
      "0.03886185958981514\n",
      "0.03683628886938095\n",
      "epoch:9\n",
      "0.04173470288515091\n",
      "0.03966717794537544\n",
      "0.03725501522421837\n",
      "0.035292115062475204\n",
      "epoch:0\n",
      "56666472.0\n",
      "37103732.0\n",
      "58654508.0\n",
      "42924616.0\n",
      "epoch:1\n",
      "35996128.0\n",
      "20497060.0\n",
      "52510456.0\n",
      "32498636.0\n",
      "epoch:2\n",
      "29761850.0\n",
      "15432262.0\n",
      "46255428.0\n",
      "28149204.0\n",
      "epoch:3\n",
      "25805160.0\n",
      "12959797.0\n",
      "40071880.0\n",
      "25310966.0\n",
      "epoch:4\n",
      "23177106.0\n",
      "11434417.0\n",
      "34894848.0\n",
      "23203008.0\n",
      "epoch:5\n",
      "21437946.0\n",
      "10422889.0\n",
      "30681274.0\n",
      "21567014.0\n",
      "epoch:6\n",
      "20292586.0\n",
      "9748147.0\n",
      "27236278.0\n",
      "20286548.0\n",
      "epoch:7\n",
      "19542844.0\n",
      "9299797.0\n",
      "24387702.0\n",
      "19292630.0\n",
      "epoch:8\n",
      "19033608.0\n",
      "9000115.0\n",
      "22007158.0\n",
      "18528708.0\n",
      "epoch:9\n",
      "18673216.0\n",
      "8799238.0\n",
      "19996176.0\n",
      "17953040.0\n",
      "epoch:0\n",
      "39557532.0\n",
      "2701118.5\n",
      "1626908.75\n",
      "1200616.375\n",
      "epoch:1\n",
      "12636998.0\n",
      "283762.8125\n",
      "295631.59375\n",
      "271841.90625\n",
      "epoch:2\n",
      "10816678.0\n",
      "87194.1484375\n",
      "96768.1484375\n",
      "89570.890625\n",
      "epoch:3\n",
      "9666879.0\n",
      "34451.48828125\n",
      "39637.1015625\n",
      "35576.5234375\n",
      "epoch:4\n",
      "8628553.0\n",
      "15027.8232421875\n",
      "18239.025390625\n",
      "15050.173828125\n",
      "epoch:5\n",
      "7652693.5\n",
      "6593.76416015625\n",
      "8687.3779296875\n",
      "6556.5107421875\n",
      "epoch:6\n",
      "6735760.0\n",
      "2764.16552734375\n",
      "4008.413330078125\n",
      "2846.1220703125\n",
      "epoch:7\n",
      "5903323.5\n",
      "1125.0377197265625\n",
      "1803.040771484375\n",
      "1206.994140625\n",
      "epoch:8\n",
      "5185162.0\n",
      "454.4854431152344\n",
      "834.4651489257812\n",
      "536.4418334960938\n",
      "epoch:9\n",
      "4584883.5\n",
      "193.71510314941406\n",
      "357.6279296875\n",
      "238.41860961914062\n",
      "epoch:0\n",
      "88699456.0\n",
      "86587600.0\n",
      "114414480.0\n",
      "81111440.0\n",
      "epoch:1\n",
      "58420372.0\n",
      "30780746.0\n",
      "80360912.0\n",
      "37080312.0\n",
      "epoch:2\n",
      "37319240.0\n",
      "18052812.0\n",
      "62552704.0\n",
      "27806826.0\n",
      "epoch:3\n",
      "30543900.0\n",
      "14198534.0\n",
      "49644584.0\n",
      "22242764.0\n",
      "epoch:4\n",
      "27660006.0\n",
      "11436605.0\n",
      "38948648.0\n",
      "18132330.0\n",
      "epoch:5\n",
      "26253858.0\n",
      "9302806.0\n",
      "30046924.0\n",
      "15236741.0\n",
      "epoch:6\n",
      "25664894.0\n",
      "7943979.0\n",
      "23701156.0\n",
      "13277841.0\n",
      "epoch:7\n",
      "25368686.0\n",
      "7298256.0\n",
      "19300610.0\n",
      "11988695.0\n",
      "epoch:8\n",
      "24984372.0\n",
      "7088953.5\n",
      "16090754.0\n",
      "11192272.0\n",
      "epoch:9\n",
      "24412828.0\n",
      "7093593.5\n",
      "13691787.0\n",
      "10731229.0\n",
      "epoch:0\n",
      "0.2803381085395813\n",
      "0.09707539528608322\n",
      "0.06704394519329071\n",
      "0.05006008222699165\n",
      "epoch:1\n",
      "0.10397034883499146\n",
      "0.08821733295917511\n",
      "0.06268241256475449\n",
      "0.04473148658871651\n",
      "epoch:2\n",
      "0.09382925182580948\n",
      "0.075297050178051\n",
      "0.05453743413090706\n",
      "0.041175030171871185\n",
      "epoch:3\n",
      "0.07361945509910583\n",
      "0.06608399748802185\n",
      "0.04851090535521507\n",
      "0.039897430688142776\n",
      "epoch:4\n",
      "0.057568274438381195\n",
      "0.0606677420437336\n",
      "0.046804435551166534\n",
      "0.04001852869987488\n",
      "epoch:5\n",
      "0.05382049083709717\n",
      "0.05681630223989487\n",
      "0.045652471482753754\n",
      "0.04100368171930313\n",
      "epoch:6\n",
      "0.05116387456655502\n",
      "0.05081678181886673\n",
      "0.04392007738351822\n",
      "0.040768057107925415\n",
      "epoch:7\n",
      "0.0488174743950367\n",
      "0.04612812027335167\n",
      "0.04208006337285042\n",
      "0.03955460339784622\n",
      "epoch:8\n",
      "0.046782199293375015\n",
      "0.04364028200507164\n",
      "0.040488291531801224\n",
      "0.038364339619874954\n",
      "epoch:9\n",
      "0.044629741460084915\n",
      "0.04129532352089882\n",
      "0.038894157856702805\n",
      "0.03689451143145561\n",
      "epoch:0\n",
      "54857396.0\n",
      "30895964.0\n",
      "49573048.0\n",
      "29023772.0\n",
      "epoch:1\n",
      "25249014.0\n",
      "15347741.0\n",
      "37686400.0\n",
      "21860496.0\n",
      "epoch:2\n",
      "20384136.0\n",
      "11432782.0\n",
      "27854720.0\n",
      "17873148.0\n",
      "epoch:3\n",
      "18058332.0\n",
      "9483519.0\n",
      "20920908.0\n",
      "15601466.0\n",
      "epoch:4\n",
      "16795804.0\n",
      "8526254.0\n",
      "16250792.0\n",
      "14419693.0\n",
      "epoch:5\n",
      "15959872.0\n",
      "8056956.0\n",
      "13161942.0\n",
      "13908034.0\n",
      "epoch:6\n",
      "15309912.0\n",
      "7822369.5\n",
      "11086002.0\n",
      "13800758.0\n",
      "epoch:7\n",
      "14750397.0\n",
      "7692353.0\n",
      "9644513.0\n",
      "13953698.0\n",
      "epoch:8\n",
      "14220301.0\n",
      "7610733.0\n",
      "8612096.0\n",
      "14274616.0\n",
      "epoch:9\n",
      "13737291.0\n",
      "7551120.0\n",
      "7848581.0\n",
      "14727120.0\n",
      "epoch:0\n",
      "28033820.0\n",
      "169701.921875\n",
      "105917.5\n",
      "68590.0625\n",
      "epoch:1\n",
      "6906612.0\n",
      "16212.478515625\n",
      "23469.35546875\n",
      "14081.603515625\n",
      "epoch:2\n",
      "5719325.0\n",
      "4947.19091796875\n",
      "7838.02490234375\n",
      "4068.02099609375\n",
      "epoch:3\n",
      "4808853.0\n",
      "1750.888671875\n",
      "2861.031005859375\n",
      "1221.8974609375\n",
      "epoch:4\n",
      "3939526.5\n",
      "618.3987426757812\n",
      "998.3818359375\n",
      "342.72772216796875\n",
      "epoch:5\n",
      "3066834.25\n",
      "178.81405639648438\n",
      "372.5305480957031\n",
      "89.40736389160156\n",
      "epoch:6\n",
      "2276368.5\n",
      "59.60466766357422\n",
      "119.209716796875\n",
      "29.802448272705078\n",
      "epoch:7\n",
      "1646990.125\n",
      "14.901164054870605\n",
      "44.70359420776367\n",
      "3.8443879020633176e-05\n",
      "epoch:8\n",
      "1175042.25\n",
      "1.0639429319780902e-06\n",
      "14.9011869430542\n",
      "1.1066719707741868e-05\n",
      "epoch:9\n",
      "837963.25\n",
      "2.585351523975987e-07\n",
      "14.901166915893555\n",
      "3.0115247682260815e-06\n",
      "epoch:0\n",
      "88334448.0\n",
      "85871936.0\n",
      "124742488.0\n",
      "132862312.0\n",
      "epoch:1\n",
      "61075240.0\n",
      "47501276.0\n",
      "82255296.0\n",
      "31274580.0\n",
      "epoch:2\n",
      "22386660.0\n",
      "19006116.0\n",
      "59969272.0\n",
      "22950428.0\n",
      "epoch:3\n",
      "18874188.0\n",
      "16470819.0\n",
      "47853572.0\n",
      "20603964.0\n",
      "epoch:4\n",
      "20293792.0\n",
      "15607163.0\n",
      "38141528.0\n",
      "19294674.0\n",
      "epoch:5\n",
      "22859090.0\n",
      "15713046.0\n",
      "30225200.0\n",
      "18581628.0\n",
      "epoch:6\n",
      "25855566.0\n",
      "16657312.0\n",
      "23606820.0\n",
      "18468058.0\n",
      "epoch:7\n",
      "28820276.0\n",
      "17919210.0\n",
      "18434200.0\n",
      "19323686.0\n",
      "epoch:8\n",
      "31338192.0\n",
      "18879796.0\n",
      "14468322.0\n",
      "21113862.0\n",
      "epoch:9\n",
      "33407068.0\n",
      "19201564.0\n",
      "11424296.0\n",
      "23526164.0\n",
      "epoch:0\n",
      "0.34287017583847046\n",
      "0.09848751127719879\n",
      "0.06595483422279358\n",
      "0.04944542795419693\n",
      "epoch:1\n",
      "0.08814600855112076\n",
      "0.07762455195188522\n",
      "0.05921720713376999\n",
      "0.0416145995259285\n",
      "epoch:2\n",
      "0.05564014986157417\n",
      "0.05954260379076004\n",
      "0.04893018677830696\n",
      "0.041604917496442795\n",
      "epoch:3\n",
      "0.05398891121149063\n",
      "0.056300826370716095\n",
      "0.04782984405755997\n",
      "0.04173576831817627\n",
      "epoch:4\n",
      "0.053271375596523285\n",
      "0.05320854112505913\n",
      "0.04657353088259697\n",
      "0.041767336428165436\n",
      "epoch:5\n",
      "0.05256678909063339\n",
      "0.05038926750421524\n",
      "0.045251261442899704\n",
      "0.04154469445347786\n",
      "epoch:6\n",
      "0.05196777731180191\n",
      "0.04794500395655632\n",
      "0.04414097219705582\n",
      "0.0411347895860672\n",
      "epoch:7\n",
      "0.0514230951666832\n",
      "0.04695527255535126\n",
      "0.04351593181490898\n",
      "0.04070940613746643\n",
      "epoch:8\n",
      "0.05089528113603592\n",
      "0.04660077020525932\n",
      "0.043134965002536774\n",
      "0.040385909378528595\n",
      "epoch:9\n",
      "0.05069531127810478\n",
      "0.04631306603550911\n",
      "0.042816027998924255\n",
      "0.040132440626621246\n",
      "epoch:0\n",
      "60315276.0\n",
      "29075910.0\n",
      "58359220.0\n",
      "26036624.0\n",
      "epoch:1\n",
      "16661747.0\n",
      "12917495.0\n",
      "42275728.0\n",
      "17596764.0\n",
      "epoch:2\n",
      "15280323.0\n",
      "10043328.0\n",
      "28109312.0\n",
      "13143176.0\n",
      "epoch:3\n",
      "17869984.0\n",
      "8462221.0\n",
      "17437242.0\n",
      "11889322.0\n",
      "epoch:4\n",
      "19837340.0\n",
      "8482408.0\n",
      "11615645.0\n",
      "12230573.0\n",
      "epoch:5\n",
      "20397564.0\n",
      "9108798.0\n",
      "8261259.0\n",
      "13212254.0\n",
      "epoch:6\n",
      "19932930.0\n",
      "9604750.0\n",
      "6384553.5\n",
      "14412624.0\n",
      "epoch:7\n",
      "18824028.0\n",
      "9868995.0\n",
      "5320659.0\n",
      "15701021.0\n",
      "epoch:8\n",
      "17554832.0\n",
      "9965043.0\n",
      "4706565.5\n",
      "17033738.0\n",
      "epoch:9\n",
      "16329816.0\n",
      "9919386.0\n",
      "4319994.5\n",
      "18279010.0\n",
      "epoch:0\n",
      "22769886.0\n",
      "66764.703125\n",
      "38914.4375\n",
      "15810.1640625\n",
      "epoch:1\n",
      "6695088.5\n",
      "16190.130859375\n",
      "17486.55078125\n",
      "3471.98681640625\n",
      "epoch:2\n",
      "5432457.0\n",
      "7368.63427734375\n",
      "8389.3818359375\n",
      "953.6844482421875\n",
      "epoch:3\n",
      "4354362.0\n",
      "3196.30322265625\n",
      "3516.69287109375\n",
      "253.32638549804688\n",
      "epoch:4\n",
      "3295362.25\n",
      "1184.6434326171875\n",
      "1281.510986328125\n",
      "59.60871505737305\n",
      "epoch:5\n",
      "2304008.5\n",
      "357.6280517578125\n",
      "372.53369140625\n",
      "0.0018160238396376371\n",
      "epoch:6\n",
      "1505181.25\n",
      "104.30815124511719\n",
      "104.30915832519531\n",
      "0.00042123495950363576\n",
      "epoch:7\n",
      "937428.375\n",
      "29.802322387695312\n",
      "14.901273727416992\n",
      "5.849003719049506e-05\n",
      "epoch:8\n",
      "567481.0\n",
      "2.5667250724836776e-07\n",
      "7.596611794724595e-06\n",
      "5.937367859587539e-06\n",
      "epoch:9\n",
      "329446.125\n",
      "4.3213368883243675e-08\n",
      "5.595385914602957e-07\n",
      "6.541609991472797e-07\n",
      "epoch:0\n",
      "88389480.0\n",
      "82824800.0\n",
      "110288592.0\n",
      "86564160.0\n",
      "epoch:1\n",
      "53651396.0\n",
      "39433256.0\n",
      "81064856.0\n",
      "35681792.0\n",
      "epoch:2\n",
      "34322972.0\n",
      "22241496.0\n",
      "56234296.0\n",
      "22136780.0\n",
      "epoch:3\n",
      "26812608.0\n",
      "16079512.0\n",
      "38245112.0\n",
      "15502626.0\n",
      "epoch:4\n",
      "24230028.0\n",
      "12005877.0\n",
      "25669554.0\n",
      "12415800.0\n",
      "epoch:5\n",
      "23492788.0\n",
      "9416056.0\n",
      "18670814.0\n",
      "11135055.0\n",
      "epoch:6\n",
      "23089860.0\n",
      "8257827.0\n",
      "14779885.0\n",
      "10611269.0\n",
      "epoch:7\n",
      "22614088.0\n",
      "7932492.0\n",
      "12370830.0\n",
      "10452866.0\n",
      "epoch:8\n",
      "22052216.0\n",
      "7945289.5\n",
      "10763707.0\n",
      "10531046.0\n",
      "epoch:9\n",
      "21435020.0\n",
      "8051703.0\n",
      "9614058.0\n",
      "10787941.0\n",
      "epoch:0\n",
      "0.2762078046798706\n",
      "0.09736602753400803\n",
      "0.06664909422397614\n",
      "0.05080842226743698\n",
      "epoch:1\n",
      "0.09459871798753738\n",
      "0.08758951723575592\n",
      "0.05836240202188492\n",
      "0.04231095686554909\n",
      "epoch:2\n",
      "0.07509745657444\n",
      "0.07081373780965805\n",
      "0.04950649291276932\n",
      "0.04013518989086151\n",
      "epoch:3\n",
      "0.05505198985338211\n",
      "0.059843920171260834\n",
      "0.046724848449230194\n",
      "0.04071102291345596\n",
      "epoch:4\n",
      "0.053538836538791656\n",
      "0.05582745000720024\n",
      "0.04572046175599098\n",
      "0.040746189653873444\n",
      "epoch:5\n",
      "0.051662009209394455\n",
      "0.05158737301826477\n",
      "0.04412583261728287\n",
      "0.03978575021028519\n",
      "epoch:6\n",
      "0.04880006983876228\n",
      "0.04660417139530182\n",
      "0.041753046214580536\n",
      "0.038373589515686035\n",
      "epoch:7\n",
      "0.04534078389406204\n",
      "0.041775621473789215\n",
      "0.03894112631678581\n",
      "0.03640161082148552\n",
      "epoch:8\n",
      "0.043098755180835724\n",
      "0.038759730756282806\n",
      "0.0364619605243206\n",
      "0.03446197137236595\n",
      "epoch:9\n",
      "0.04136853665113449\n",
      "0.0365433432161808\n",
      "0.03465196117758751\n",
      "0.032741136848926544\n",
      "epoch:0\n",
      "54628160.0\n",
      "25398588.0\n",
      "44758944.0\n",
      "26272142.0\n",
      "epoch:1\n",
      "25509478.0\n",
      "11332059.0\n",
      "31560876.0\n",
      "18778486.0\n",
      "epoch:2\n",
      "20819804.0\n",
      "8736731.0\n",
      "22671684.0\n",
      "15302651.0\n",
      "epoch:3\n",
      "19631588.0\n",
      "7823621.0\n",
      "16779604.0\n",
      "13731968.0\n",
      "epoch:4\n",
      "19327192.0\n",
      "7533797.5\n",
      "13034547.0\n",
      "13165622.0\n",
      "epoch:5\n",
      "19137140.0\n",
      "7486093.0\n",
      "10697048.0\n",
      "13187078.0\n",
      "epoch:6\n",
      "18871092.0\n",
      "7532119.0\n",
      "9190722.0\n",
      "13510992.0\n",
      "epoch:7\n",
      "18473604.0\n",
      "7608041.5\n",
      "8164759.0\n",
      "14003386.0\n",
      "epoch:8\n",
      "18064162.0\n",
      "7672664.0\n",
      "7430085.5\n",
      "14588734.0\n",
      "epoch:9\n",
      "17607204.0\n",
      "7710326.5\n",
      "6876069.5\n",
      "15233437.0\n",
      "epoch:0\n",
      "33685108.0\n",
      "99435.4921875\n",
      "54590.44921875\n",
      "38422.66015625\n",
      "epoch:1\n",
      "12545726.0\n",
      "9894.384765625\n",
      "12233.8759765625\n",
      "7428.2373046875\n",
      "epoch:2\n",
      "10725266.0\n",
      "2942.98486328125\n",
      "4261.74560546875\n",
      "2041.464111328125\n",
      "epoch:3\n",
      "9190495.0\n",
      "1005.8302612304688\n",
      "1639.135009765625\n",
      "610.9503784179688\n",
      "epoch:4\n",
      "7656419.0\n",
      "327.8260192871094\n",
      "625.8519287109375\n",
      "178.8152313232422\n",
      "epoch:5\n",
      "6029794.5\n",
      "104.3082275390625\n",
      "223.51834106445312\n",
      "29.802785873413086\n",
      "epoch:6\n",
      "4574418.5\n",
      "14.901178359985352\n",
      "74.50599670410156\n",
      "0.00013446249067783356\n",
      "epoch:7\n",
      "3401743.5\n",
      "3.374740572326118e-06\n",
      "29.802358627319336\n",
      "3.463961184024811e-05\n",
      "epoch:8\n",
      "2496849.75\n",
      "7.383525257864676e-07\n",
      "14.901166915893555\n",
      "8.456036084680818e-06\n",
      "epoch:9\n",
      "1819530.625\n",
      "1.9520521732374618e-07\n",
      "1.244619511453493e-06\n",
      "2.0079314708709717e-06\n"
     ]
    }
   ],
   "source": [
    "val_losses = []\n",
    "for architecture, loss_func in itertools.product(*[[Net(1), Net(2), Net(3), Net(4)],\n",
    "                                     [loss1, loss2, loss3, loss4]]):\n",
    "    val_losses.append(tuning(architecture, loss_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "0.03682646167632673\n"
     ]
    }
   ],
   "source": [
    "best_i = 0\n",
    "best_error = np.Inf\n",
    "for i in range(len(val_losses)):\n",
    "    if np.mean(val_losses[i]) < best_error:\n",
    "        best_i = i\n",
    "        best_error = np.mean(val_losses[i])\n",
    "print(i)\n",
    "print(best_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 17, 4, 4])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(a,64)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[6.8608e+02, 1.6832e+04, 1.1194e+03, 1.9181e+04, 2.7628e+06, 5.2306e+04,\n",
       "          1.6109e+03, 5.7940e+04, 3.1252e+03, 1.1940e+03]],\n",
       "        grad_fn=<ExpBackward0>),\n",
       " tensor([[1.6154e-03, 7.8157e-05, 1.2027e-03, 5.5434e-05, 9.1532e-07, 9.0809e-05,\n",
       "          8.8335e-04, 6.4726e-05, 2.0962e-03, 1.0000e+00]],\n",
       "        grad_fn=<ExpBackward0>))"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network(torch.FloatTensor(root_node.next_nodes[4].state).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]],\n",
       "\n",
       "       [[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]]])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_node.next_nodes[4].state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
